{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# クラウドへ（そしてその先へ）\n数値の問題を解決する方法については十分に検討しました。トレーニング部分をクラウドに移行します。（数値の問題ではこれ以上はローカルでの実行は不要ですが、他の問題については、ローカルでサブセットの問題をテストしてからクラウドに移動して全体を処理します）\n\nいくつか設定しましょう。\n\n最初にしなければならないことは、azureml.core パッケージがノートブック環境にインストールされているのを確認することです。Azure Notebooksを使用している場合は、簡単な2ステップのプロセスで確認できます。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Azure Notebooks に依存関係を追加する\n\"Project Settings\" をクリックします。\n\n![Project Setings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/project_settings.png)\n\n次に、\"Environment\" タブでドロップダウンリストを左から順に `Requirements.txt` 、 `requirements.txt` 、 `Python 3.6` を選択します。\n\n![Settings](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/settings.png)\n\nこれらのステップで、実行できるようになるはずです。\n\n**注** もし上記の設定をしても問題が発生する場合は、Notebook でカーネルが Python 3.6 に設定されていることを確認してください。Python 3.6 になっていない場合は、次の操作で設定変更できます: ノートブックのメニューで [Kernel] -[Change Kernel] - [Python 3.6] を選択"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import json, os, sys\nimport time\nimport azureml\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace, Run, Experiment\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.dnn import PyTorch\n#from azureml.widgets import RunDetails\n#from torchvision import datasets, transforms\n\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Azure ML SDK Version:  1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Azure Machine Learning サービス（AzureML Service）のワークスペースを設定する"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## AzureML Service ワークスペース を作成する\n最初に必要な作業は、Azure Machine Learning サービス ワークスペースの作成です。\n以下の Python コードから AzureML Service のワークスペースを作成します。\n\n以下の Python スクリプトで\n- `ワークスペース名`\n- `リソースグループ名`\n- `AzureサブスクリプションID` \n- `Azureのリージョン`\n\nの4つの値を適宜設定して実行します。\n\nワークスペース名やリソースグループ名は、ご自身のAzure環境の中で区別できるものを任意で設定。\nAzureサブスクリプションIDには、Azureポータルで左メニューから「サブスクリプション」を選び、一覧表示されるサブスクリプションの中でワークスペースを作成する先のものを選んでコピー＆ペーストします。\nリージョンについては、AzureML Service が利用できるリージョンを設定します。\n\n既に AzureML Service ワークスペース を作成済みでそれを利用したい場合は、そのワークスペースの情報を設定しても構いません。\n\nスクリプトを実行すると `config.json` ファイルに設定が書き出されます。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "config = {}\nconfig[\"workspace_name\"] = \"decode2019_mlops\"\nconfig[\"resource_group\"] = \"decode2019\"\nconfig[\"subscription_id\"] = \"cd5e54ba-5b64-4acb-8ae5-72654d870add\"\nconfig[\"location\"] = \"southcentralus\"\n\nwith open('config.json', 'w') as f:\n    json.dump(config, f)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "もし上記で設定した AzureML Service の ワークスペース に接続し、存在しない場合は新規に作成します。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.authentication import InteractiveLoginAuthentication\n\nprint(\"SDK Version:\", azureml.core.VERSION)\n#with open(\"aml_config/config.json\") as f:\n #   config = json.load(f)\n\nworkspace_name = config[\"workspace_name\"]\nresource_group = config[\"resource_group\"]\nsubscription_id = config[\"subscription_id\"]\nlocation = config[\"location\"]\n\ncli_auth = InteractiveLoginAuthentication()\n\ntry:\n    ws = Workspace.get(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=cli_auth\n    )\n\nexcept:\n    # this call might take a minute or two.\n    print(\"Creating new workspace...\")\n    ws = Workspace.create(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        # create_resource_group=True,\n        location=location,\n        auth=cli_auth\n    )\n\n# print Workspace details\nprint(\"\\nWorkspace configuration succeeded. You are all set!\")\nprint(\"Using workspace below;\")\nprint(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK Version: 1.0.33\n\nWorkspace configuration succeeded. You are all set!\nUsing workspace below;\ndecode2019_mlops\ndecode2019\nsouthcentralus\ncd5e54ba-5b64-4acb-8ae5-72654d870add\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# クラウドコンピュート\n次に、実験用のコンピュートターゲットを定義する必要があります。これは新規のワークスペースなので、クラスタの名前は自由に変更してください（私は 'racer' と呼んでいます）。以下のコードは自分のクラスタへの参照を取得しようとしますが、存在しない場合は作成します。クラスタを作成する場合、少し時間がかかります。また、予想外の課金をされないように、実験が完了したらクラスターをオフにしてください（実際には、min_node を 0 に設定して、長時間アイドル状態になるとクラスタが自動的にオフになる設定を検討してください）。 \n\n**訳注** Azure の無償評価版などの GPU 最適化済みマシンを利用できない場合、またはコストを抑えたい場合は、vm_size を \"STANDARD_D2_V2\" にしてください。min_nodes を 1 以上にすると、訓練開始までの待ち時間を短縮できますが、コンピュートの削除し忘れなどで課金が継続されることがあるので注意してください。min_nodes を 0 にすると実行が終わると自動的にノードが削除されて課金されなくなります。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cluster = 'decode2019-MLOps'\ntry:\n    compute = ComputeTarget(workspace=ws, name=cluster)\n    print('Found existing compute target \"{}\"'.format(cluster))\nexcept ComputeTargetException:\n    print('Creating new compute target \"{}\"...'.format(cluster))\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=0, max_nodes=6)\n    compute = ComputeTarget.create(ws, cluster, compute_config)\n    compute.wait_for_completion(show_output=True)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target \"decode2019-MLOps\"\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 実験の時間\n今回はAutomated Machine Learningを利用して実験を行います。\n次の4行を実行して、何が起こるのか見てみましょう。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create a project_folder if it doesn't exist\nproject_folder = \"automl\"\n\nif not os.path.exists(project_folder):\n    os.makedirs(project_folder)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#%%writefile $project_folder/get_data.py\n\n#from sklearn import datasets\n#from scipy import sparse\n#import numpy as np\n\n#def get_data():\n    \n#    digits = datasets.load_digits()\n#    X_digits = digits.data[10:,:]\n#    y_digits = digits.target[10:]\n\n#    return { \"X\" : X_digits, \"y\" : y_digits }",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\nimport time\nimport logging\n\nautoml_settings = {\n    \"name\": \"AutoML_Demo_Experiment_{0}\".format(time.time()),\n    \"iteration_timeout_minutes\": 10,\n    \"iterations\": 1,\n    \"n_cross_validations\": 5,\n    \"primary_metric\": 'AUC_weighted',\n    \"preprocess\": False,\n    \"max_concurrent_iterations\": 10,\n    \"verbosity\": logging.INFO\n}\n\nautoml_config = AutoMLConfig(task='classification',\n                             debug_log='automl_errors.log',\n                             path=project_folder,\n                             compute_target = compute,\n                             data_script=project_folder + \"/get_data.py\",\n                             **automl_settings,\n                            )",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.experiment import Experiment\nexperiment=Experiment(ws, 'automl_remote')\nrun = experiment.submit(automl_config, show_output=True)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running on remote compute: decode2019-MLOps\nParent Run ID: AutoML_5657eb12-b33a-42ff-bad4-167797613457\n****************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n****************************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   StandardScalerWrapper SGD                      0:00:24       0.9949    0.9949\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "run.wait_for_completion()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "{'runId': 'AutoML_5657eb12-b33a-42ff-bad4-167797613457',\n 'target': 'decode2019-MLOps',\n 'status': 'Completed',\n 'startTimeUtc': '2019-05-15T05:38:22.879166Z',\n 'endTimeUtc': '2019-05-15T05:38:52.629621Z',\n 'properties': {'num_iterations': '1',\n  'training_type': 'TrainFull',\n  'acquisition_function': 'EI',\n  'primary_metric': 'AUC_weighted',\n  'train_split': '0',\n  'MaxTimeSeconds': '600',\n  'acquisition_parameter': '0',\n  'num_cross_validation': '5',\n  'target': 'decode2019-MLOps',\n  'RawAMLSettingsString': \"{'name': 'AutoML_Demo_Experiment_1557898354.230591', 'path': 'automl', 'subscription_id': 'cd5e54ba-5b64-4acb-8ae5-72654d870add', 'resource_group': 'decode2019', 'workspace_name': 'decode2019_mlops', 'region': 'southcentralus', 'compute_target': 'decode2019-MLOps', 'spark_service': None, 'iterations': 1, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': 'automl/get_data.py', 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': None, 'preprocess': False, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 10, 'iteration_timeout_minutes': 10, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'XGBoostClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_feature_sweeping': True, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': False, 'enable_stack_ensembling': False, 'ensemble_iterations': None, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\",\n  'AMLSettingsJsonString': '{\\n  \"name\": \"AutoML_Demo_Experiment_1557898354.230591\",\\n  \"path\": \"automl\",\\n  \"subscription_id\": \"cd5e54ba-5b64-4acb-8ae5-72654d870add\",\\n  \"resource_group\": \"decode2019\",\\n  \"workspace_name\": \"decode2019_mlops\",\\n  \"region\": \"southcentralus\",\\n  \"compute_target\": \"decode2019-MLOps\",\\n  \"spark_service\": null,\\n  \"iterations\": 1,\\n  \"primary_metric\": \"AUC_weighted\",\\n  \"task_type\": \"classification\",\\n  \"data_script\": \"automl/get_data.py\",\\n  \"validation_size\": 0.0,\\n  \"n_cross_validations\": 5,\\n  \"y_min\": null,\\n  \"y_max\": null,\\n  \"num_classes\": null,\\n  \"preprocess\": false,\\n  \"lag_length\": 0,\\n  \"is_timeseries\": false,\\n  \"max_cores_per_iteration\": 1,\\n  \"max_concurrent_iterations\": 10,\\n  \"iteration_timeout_minutes\": 10,\\n  \"mem_in_mb\": null,\\n  \"enforce_time_on_windows\": false,\\n  \"experiment_timeout_minutes\": null,\\n  \"experiment_exit_score\": null,\\n  \"whitelist_models\": null,\\n  \"blacklist_algos\": [\\n    \"XGBoostClassifier\",\\n    \"XGBoostClassifier\"\\n  ],\\n  \"auto_blacklist\": true,\\n  \"blacklist_samples_reached\": false,\\n  \"exclude_nan_labels\": true,\\n  \"verbosity\": 20,\\n  \"debug_log\": \"automl_errors.log\",\\n  \"show_warnings\": false,\\n  \"model_explainability\": false,\\n  \"service_url\": null,\\n  \"sdk_url\": null,\\n  \"sdk_packages\": null,\\n  \"enable_onnx_compatible_models\": false,\\n  \"enable_feature_sweeping\": true,\\n  \"telemetry_verbosity\": \"INFO\",\\n  \"send_telemetry\": true,\\n  \"enable_early_stopping\": false,\\n  \"early_stopping_n_iters\": 10,\\n  \"metrics\": null,\\n  \"enable_ensembling\": false,\\n  \"enable_stack_ensembling\": false,\\n  \"ensemble_iterations\": null,\\n  \"enable_tf\": false,\\n  \"enable_cache\": true,\\n  \"enable_subsampling\": false,\\n  \"subsample_seed\": null,\\n  \"cost_mode\": 0,\\n  \"metric_operation\": \"maximize\"\\n}',\n  'DataPrepJsonString': None,\n  'EnableSubsampling': 'False',\n  'runTemplate': 'AutoML',\n  'azureml.runsource': 'automl',\n  'display_task_type': 'classification',\n  'dependencies_versions': '{\"azureml-widgets\": \"1.0.33\", \"azureml-train\": \"1.0.33\", \"azureml-train-restclients-hyperdrive\": \"1.0.33\", \"azureml-train-core\": \"1.0.33\", \"azureml-train-automl\": \"1.0.33\", \"azureml-telemetry\": \"1.0.33\", \"azureml-sdk\": \"1.0.33\", \"azureml-pipeline\": \"1.0.33\", \"azureml-pipeline-steps\": \"1.0.33\", \"azureml-pipeline-core\": \"1.0.33\", \"azureml-explain-model\": \"1.0.33\", \"azureml-dataprep\": \"1.1.2\", \"azureml-dataprep-native\": \"12.0.1\", \"azureml-core\": \"1.0.33.1\", \"azureml-contrib-opendatasets\": \"1.0.33\", \"azureml-contrib-notebook\": \"1.0.33\"}',\n  'ContentSnapshotId': '4828886a-09bd-4c43-9684-4c47090ebdca',\n  'snapshotId': '4828886a-09bd-4c43-9684-4c47090ebdca',\n  'SetupRunId': 'AutoML_5657eb12-b33a-42ff-bad4-167797613457_setup',\n  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 10, \"dataset_features\": 64, \"dataset_samples\": 1787, \"is_sparse\": false, \"subsampling\": false}',\n  'azureml.git.repository_uri': 'https://github.com/KazukiYamamoto/decode2019-Azure-MLOps.git',\n  'azureml.git.branch': 'master',\n  'azureml.git.commit': 'c8f77907d1ca4285dbaa70fa23a8d25318601642',\n  'azureml.git.dirty': 'False',\n  'azureml.git.build_id': None,\n  'azureml.git.build_uri': None,\n  'mlflow.source.git.branch': 'master',\n  'mlflow.source.git.commit': 'c8f77907d1ca4285dbaa70fa23a8d25318601642',\n  'mlflow.source.git.repoURL': 'https://github.com/KazukiYamamoto/decode2019-Azure-MLOps.git'},\n 'logFiles': {}}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "すべて完了すると、次のようになります:\n\n![AzureML Run](https://raw.githubusercontent.com/sethjuarez/pytorchintro/master/images/run_widget.png)\n\n実際に、損失関数は時間の経過とともに（平均して）減少し、モデルの精度が上がることに注意してください。learning_rate パラメータを変更して試してみてください。詳しくは、[Azure Machine Learning service でモデルのハイパーパラメーターを調整する](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) を参照してください。\n\nさて、どのようにしてこれらの素晴らしいチャートが表示できたのか疑問に思うかもしれません。これは Azure ML サービスが、実験結果に対して実用的な価値を付加してくれるところです。[いくつか](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L156-L166) の [戦略的](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L121-L122) に [配置](https://github.com/sethjuarez/pytorchintro/blob/master/train.py#L142-L143) されたログステートメントを使用して、Azure ML サービスはこの出力を作成しました。実際、値が複数回ログに記録されると、テーブル内の項目ではなくチャートが自動的に作成されます。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# モデル\nトレーニングがすべて完了して出力が完了したら、実際に特定の実験のすべての実行の出力を確認し、それを「公式な」ワークスペースモデルに昇格させることができます。重要なファイル（つまり私たちをお金持ちにしてくれるかもしれないモデル）が通常 Jeff という名前のコンピュータ上に置かれるのは素晴らしい機能です。現在は、多くの人がモデルのバージョン管理さえしていませんが、以下のコードを実行してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = run.get_output()\nprint(best_run.get_file_names())",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['accuracy_table', 'automl_driver.py', 'azureml-logs/55_batchai_execution.txt', 'azureml-logs/60_control_log.txt', 'azureml-logs/80_driver_log.txt', 'azureml-logs/azureml.log', 'confusion_matrix', 'outputs/env_dependencies.json', 'outputs/model.pkl']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model = best_run.register_model(model_name='mnist-AutoML', model_path='outputs/model.pkl')\nprint(model.name, model.id, model.version, sep = '\\t')",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "mnist-AutoML\tmnist-AutoML:3\t3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# イメージ\nモデルが完成したので、それをプロダクションで使用する場合は、モデルの使用方法を定義する必要があります。これはスコアリングまたは推論とも呼ばれます。Azure ML サービスでは、基本的に2つのメソッドが必要です:\n1. `init()`\n2. `run(raw)` - JSON 文字列を取り込んで予測を返す\n\n最初にスコアリングスクリプトが実行される環境を記述し、それを設定ファイルにまとめる必要があります。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "myenv = CondaDependencies()\nmyenv.add_pip_package('numpy')\nmyenv.add_pip_package('torch')\nmyenv.add_pip_package('scikit-learn')\nwith open('pytorchmnist.yml','w') as f:\n    print('Writing out {}'.format('pytorchmnist.yml'))\n    f.write(myenv.serialize_to_string())\n    print('Done!')",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Writing out pytorchmnist.yml\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "次に、Azure ML サービスにスコアリングスクリプトの場所を通知する必要があります。score.py を [あらかじめ作っておきました](score.py)。ファイルを見ると、init() メソッドと run(raw) メソッドの両方が簡単に見つかるはずです。ファイルをローカルで実行して、正しい動作をしていることを確認することもできます。\n\nこれですべてが完成したので、イメージを作成しましょう。\n\n### バックグラウンドで何をしてるか気にしないのであれば、ここは読む必要はありません\n基本的には、定義からdockerイメージを作成して、Workspace に表示される Azure Container Registry にプッシュします。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**注** しばらく時間がかかります"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.image import ContainerImage, Image\n\n# イメージの作成\nimage_config = ContainerImage.image_configuration(execution_script=\"scoreautoml.py\", \n                                runtime=\"python\", \n                                conda_file=\"pytorchmnist.yml\")\n\nimage = Image.create(ws, 'pytorchmnist', [model], image_config)\nimage.wait_for_creation(show_output=True)",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\nRunning.............................................\nSucceededImage creation operation finished for image pytorchmnist:9, operation \"Succeeded\"\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# デプロイ\nイメージ作成をせずに、残りの展開プロセスを Azure Pipelines のようなものに移動したいかもしれません。そうではなくて、このサービスを引き続きワークスペースにデプロイしたい場合は、以下を使用してください。"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import Webservice, AciWebservice\n\nservice_name = 'pytorchmnist-svc-automl3'\n\n# check for existing service\nsvcs = [svc for svc in Webservice.list(ws) if svc.name==service_name]\nif len(svcs) == 1:\n    print('Deleting prior {} deployment'.format(service_name))\n    svcs[0].delete()\n\n# create service\naciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n                                            memory_gb=1, \n                                            description='simple MNIST digit detection')\nservice = Webservice.deploy_from_image(workspace=ws, \n                                    image=image, \n                                    name=service_name, \n                                    deployment_config=aciconfig)\nservice.wait_for_deployment(show_output=True)\nprint(service.scoring_uri)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating service\nRunning............................................................................................................................................................................................................................................\nTimedOutACI service creation operation finished, operation \"TimedOut\"\nService creation polling reached terminal state, current service state: Transitioning\nService creation polling reached terminal state, unexpected response received.\nNone\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "イメージを ACI またはワークスペース Kubernetes クラスターにプッシュすることもできます。\n\n時々うまくいかないことがあります・・・もし実行時にそうなったら、実際の [logs](deploy.log) を見てください。!"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "with open('deploy.log','w') as f:\n    f.write(service.get_logs())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# サービスの実行\n以上でサービスは動作しています。適切に動作しているか見てみましょう。前から使っているテストデータをロードしてランダムな数字で試すことができます。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#digits = datasets.MNIST('data', train=True, download=True,\n#                        transform=transforms.Compose([\n#                            transforms.ToTensor(),\n#                            transforms.Lambda(lambda x: x.reshape(28*28))\n#                        ]),\n#                        target_transform=transforms.Compose([\n#                            transforms.Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, y, 1))\n#                        ])\n#                     )\n#print(len(digits))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "インデックスとして基本的に最大60,000まで任意の数を選ぶことができます。サービスがどのように動作しているかを見るために何回か試してみてください。"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#import torch\n#from PIL import Image\n#import matplotlib.pyplot as plt\n\n#X, Y = digits[57435]\n#X = X * 255\n#plt.imshow(255 - X.reshape(28,28), cmap='gray')\n#print(Y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# ポストしようとしているエンドポイントの場所\n#image_str = ','.join(map(str, X.int().tolist()))\n#print(image_str)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#import json\n#import requests\n#service_url = service.scoring_uri\n#print(service_url)\n#r = requests.post(service_url, json={'image': image_str })\n#r.json()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 最後に\nこの小さな旅が参考になっていればうれしいです！ 私の目標は、機械学習の基本がそれほど悪いものではないと理解してもらうことです。コメント、提案、または分からないところは一言教えてください。"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}